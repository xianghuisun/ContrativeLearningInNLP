- spearman系数不关心具体的数值，关注的是每一个数值在变量内的排序顺序
- 对比表示学习的目标是学习一个向量表示空间，在这个空间中，相似样本的距离很近，不相似样本的距离很远
- 自监督学习中有个词汇pretext task。一般翻译为代理任务或者前置任务，为了达到特定训练目标而设计的任务，pretext task会生成一个伪标签（pseudo label来自于数据本身），**使得监督学习的方式可以处理无监督数据，使用pretext task后训练的模型可以作为预训练模型供下游任务使用**。比如rotation，MLM，NSP，auto-regressive LM(GPT)等等。
- 对比学习中的pretext task就是利用原始的sentence or image作为anchor，对其进行数据增强，anchor增强后的样本与锚样本是positive的，同一个batch中的其它样本或者整个数据集的其它样本都可以作为负样本。
- **根据训练过程中负样本的收集方式不同（指的是在计算loss时负样本从何而来）**，可以将基于对比学习的架构分成多类。常用的两类是end-to-end和momentum encoder，其中end-to-end在NLP中最为常用。
- 基于判别式的模型需要标签，生成式模型目的是重构原始input，与这两种方法不同，对比学习目的是对比输入样本的相似性，因此输入的样本必须是成对的。



为什么对比学习后的向量质量比较高？从alignment和uniformity两个角度考虑。

alignment指的是在这个单位超球面空间中，相似样本投影在单位超球面中的距离越近越好，**即相似样本在这恶鬼空间中应该有相似特征**。

uniformity指的是在这个单位超球面空间中，所有样本的特征分布应该保留最多的信息。**保留更多的信息体现在所有样本在单位超球面的空间中的特征分布应该是尽可能的均匀的，即每一个样本的特征应该或多或少都有些差异。每一个样本对应的特征都应该保留了这个样本相比于其余样本的独特信息。**

uniformaity的极端例子就是将很多个样本映射在同一个点上，显然此时分布不均匀，保留的信息特别少，因为这么多样本和一个样本没什么区别。



==对比学习其实就是同时在优化特征空间中的alignment和uniformity两个属性==

alignment的loss形式如下：


$$
L_{align}\propto \mathbb{E}_{(x,y)\sim p_{pos}}\left\|f(x)-f(y)\right\|_2^2
$$
uniformity的loss形式如下：
$$
L_{uniform}\propto \log \mathbb{E}_{(x,y)\sim p_{data}}e^{-2\left\|f(x)-f(y)\right\|_2^2}
$$
alignment的loss越低，等价于$\left\|f(x)-f(y)\right\|_2^2$​的数值越低。

uniformity的loss越低，等价于$\left\|f(x)-f(y)\right\|_2^2$的数值越高，该数值越高，那么$e^x$的数值越低，此时$\log x $的数值越低。需要注意的是uniformity的loss是负数。

contrastive loss的分母就是在推开不相似样本的距离，相当于增大不相似样本的特征差异，使得最终整体单位超球面的分布空间更加均匀。



**为什么要采用余弦相似度？或者为什么要先L2规范化后再做点积？**

研究表明，将样本的特征表示映射在单位超球面上有很多好处：

1. 点积运算带有向量长度信息在里面，在去掉向量长度的单位向量上操作有利于深度学习模型训练的稳定
2. 另外就是，将表示向量映射在单位超球面上，有助于分类。因为如果模型表示能力够好，那么所有样本映射在单位超球面上后，相似样本（或者说同一个类的样本）会聚类在一簇内，最终利用线性分类器就可以区分不同类别的样本